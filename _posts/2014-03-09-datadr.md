---
layout: post
title:  "STAT 585X - datadr"
date:   2014-03-09 2:03:18
categories: blog
---

(This is a blog post made for the eight reading assignment in STAT 585X.)

Many of the ideas behind datadr closely relate to those underlying plyr and dplyr. The primary way is the divide-and-conquer approach. The plyr way is termed split-apply-combine. datadr has a similar method, which they call divide and recombine.

The divide function works much like the group_by function in plyr. A data frame is passed in, and a specification of the column to divide by is given. Also similar to dplyr, the returned object is not a data frame, but rather a particular extension of a data frame (in dplyr, this is called a grouped data frame). In this case, the object is called a ddf object.

The recombine function plays the roll of the summarise function in dplyr. A particular function is applied to each subset of the data, and then the results are recombined into the data structure of choice, a list by default.

It seems to be that the primary benefit of datadr is the choice of backends it offers, similarly to dplyr. In this case, the tutorial suggests that for small datasets, using R as the computational backend is sufficient. But for very large datasets, hadoop can be used as a backend. If hadoop is installed on a cluster of nodes, then theoretically computations done on large datasets can be done in parallel, which can drastically speed up the time relative to running it on a local machine, even if that machine is multi-core. All in all, it seems the goals and implementation styles of datadr and dplyr/plyr are very strongly aligned.
